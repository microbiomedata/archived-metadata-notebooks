{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pds\n",
    "import json\n",
    "from rdflib import Graph, RDFS, RDF, OWL, URIRef, Literal\n",
    "from hashlib import md5\n",
    "from pandasql import sqldf\n",
    "\n",
    "def pysqldf(q):\n",
    "    return sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from classificaiton paths file `GOLD_Ecosystem_Classification_Paths_10152019.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathsdf = pds.read_excel(\"data/GOLD_Ecosystem_Classification_Paths_10152019.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize column names to lower case and trim/strip spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_columns = [c.lower().strip() for c in pathsdf.columns]\n",
    "# clean_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathsdf.columns = clean_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data: \n",
    "* replace with nan with empyt string\n",
    "* make all values lowercase \n",
    "* trim spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecosystem</th>\n",
       "      <th>ecosystem_category</th>\n",
       "      <th>ecosystem_type</th>\n",
       "      <th>ecosystem_subtype</th>\n",
       "      <th>specific_ecosystem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>engineered</td>\n",
       "      <td>bioreactor</td>\n",
       "      <td>aerobic</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>unclassified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>engineered</td>\n",
       "      <td>bioreactor</td>\n",
       "      <td>anaerobic</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>unclassified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>engineered</td>\n",
       "      <td>bioreactor</td>\n",
       "      <td>continuous culture</td>\n",
       "      <td>marine intertidal flat sediment inoculum</td>\n",
       "      <td>wadden sea-germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>engineered</td>\n",
       "      <td>bioreactor</td>\n",
       "      <td>continuous culture</td>\n",
       "      <td>marine sediment inoculum</td>\n",
       "      <td>wadden sea-germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>engineered</td>\n",
       "      <td>bioreactor</td>\n",
       "      <td>continuous culture</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>unclassified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ecosystem ecosystem_category      ecosystem_type  \\\n",
       "0  engineered         bioreactor             aerobic   \n",
       "1  engineered         bioreactor           anaerobic   \n",
       "2  engineered         bioreactor  continuous culture   \n",
       "3  engineered         bioreactor  continuous culture   \n",
       "4  engineered         bioreactor  continuous culture   \n",
       "\n",
       "                          ecosystem_subtype  specific_ecosystem  \n",
       "0                              unclassified        unclassified  \n",
       "1                              unclassified        unclassified  \n",
       "2  marine intertidal flat sediment inoculum  wadden sea-germany  \n",
       "3                  marine sediment inoculum  wadden sea-germany  \n",
       "4                              unclassified        unclassified  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathsdf.fillna(\"\", inplace=True)\n",
    "pathsdf = pathsdf.applymap(lambda x: \"\" if \"(null)\" == x else x)\n",
    "pathsdf = pathsdf.applymap(lambda x: x.lower().strip())    \n",
    "pathsdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build dataframe of unique label paths and their checksums\n",
    "#### For example: 'enviromental > aquatic > freshwater > sediment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper functions for creating label path, hash, and iri\n",
    "def make_label_path(row, include_missing=False):\n",
    "    path_list = list(row)\n",
    "    temp = [e for e in path_list if e != \"\"] # remove all empty strings\n",
    "    if len(temp) > 0:\n",
    "        if include_missing:\n",
    "            ## if the value in the list an empty string (e.g., ['host-associated', 'plants', 'endosphere', ''])\n",
    "            ## this will put an \" > \" it (e.g., host-associated > plants > endosphere >)\n",
    "            return \" > \".join(path_list)\n",
    "        else:\n",
    "            ## this only retuns a path devoid of empty string\n",
    "            ## e.g, ['host-associated', 'plants', 'endosphere', ''] returns host-associated > plants > endosphere\n",
    "            return \" > \".join(temp)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def make_parent_label_path(label_path):\n",
    "    path_list = label_path.split(\" > \")\n",
    "    if len(path_list) > 1:\n",
    "        temp = path_list[0:-1]\n",
    "        return \" > \".join(temp)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def make_row_list(row, subset_list=[]):\n",
    "    if len(subset_list) > 0:  # only get values in subset list\n",
    "        row_list = [v for k,v in row.to_dict().items() \n",
    "                    if k in subset_list]\n",
    "    else:\n",
    "        row_list = list(row)\n",
    "    return row_list\n",
    "\n",
    "\n",
    "def make_row_hash(row, subset_list=[]):\n",
    "    row_list = make_row_list(row, subset_list)\n",
    "    \n",
    "    temp = [\"\" if pds.isnull(e) else e for e in row_list] # replace NaNs with ''\n",
    "    temp = \"\".join(temp)\n",
    "#     print(\"row: \", temp)\n",
    "    return make_hash(temp)\n",
    "\n",
    "\n",
    "def make_parent_hash(row, subset_list=[]):\n",
    "    row_list = make_row_list(row, subset_list)\n",
    "    row_list = row_list[0:-1] # to get the parent, exclude last value in list\n",
    "\n",
    "    temp = [\"\" if pds.isnull(e) else e for e in row_list] # replace NaNs with ''\n",
    "    temp = \"\".join(temp)\n",
    "#     print(\"parent: \", temp)\n",
    "    return make_hash(temp)\n",
    "\n",
    "\n",
    "def make_hash(val):\n",
    "    if len(val) > 0:\n",
    "        hash = md5(val.encode('utf-8'))\n",
    "        return str(hash.hexdigest())\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def make_iri(val, prefix=\"http://purl.obolibrary.org/obo/GOLD_\"):\n",
    "    if None != val and len(val) > 0:\n",
    "#         hash = make_hash(val)\n",
    "        return f\"{prefix}{val}\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def make_annotation_dict(value_list, prefix=\"http://purl.obolibrary.org/obo/GOLD_\"):\n",
    "    annotation_dict = {}\n",
    "    for val in value_list:\n",
    "        val = str(val).lower().strip()\n",
    "        annotation_dict[val] = \\\n",
    "            {'iri': make_iri(str(val), prefix=prefix), 'label': val}\n",
    "    return annotation_dict\n",
    "\n",
    "\n",
    "def make_json_annotation(row, annotation_dict):\n",
    "    annotation_value_dict = {}\n",
    "    annotation_dict_keys = annotation_dict.keys()\n",
    "    for k,v in row.to_dict().items():\n",
    "        k = str(k).lower().strip()\n",
    "        if v != \"\" and (k in annotation_dict_keys):\n",
    "            annotation_value_dict[annotation_dict[k]['iri']] = v\n",
    "    return json.dumps(annotation_value_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontdf = pds.DataFrame(columns=['label_path', 'parent_label_path', 'iri', 'parent_iri', 'annotation'])\n",
    "cols = pathsdf.columns\n",
    "annotation_dict = make_annotation_dict(cols)\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    df = pathsdf[cols[0:i + 1]].fillna(\"\").drop_duplicates()\n",
    "    df['label_path'] = df.apply(lambda row: make_label_path(row), axis=1)\n",
    "    df['row_hash'] = df.apply(lambda row: make_row_hash(row, subset_list=clean_columns), axis=1)\n",
    "    \n",
    "    df['parent_label_path'] = df.apply(lambda row: make_parent_label_path(row['label_path']), axis=1)\n",
    "    df['parent_hash'] = df.apply(lambda row: make_parent_hash(row, subset_list=clean_columns), axis=1)\n",
    "    \n",
    "    df['iri'] = df.apply(lambda row: make_iri(row['row_hash']), axis=1)\n",
    "    df['parent_iri'] = df.apply(lambda row: make_iri(row['parent_hash']), axis=1)\n",
    "    \n",
    "    df['annotation'] = df.apply(lambda row: make_json_annotation(row, annotation_dict), axis=1)\n",
    "    ontdf = ontdf.append(df[['label_path', 'parent_label_path', 'iri', 'parent_iri', 'annotation']]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visually examine output\n",
    "# pds.set_option('max_rows', None)\n",
    "# pds.set_option('display.max_colwidth', 1000)\n",
    "# print(ontdf[['label_path', 'parent_label_path']])\n",
    "# print(len(ontdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use rdflib to build ontology from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph() # instantiate graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create annotaiton properties for each of the columns (saved in the annotation dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in annotation_dict.items():\n",
    "    ## note: the value is a dict with keys 'iri' and 'label'\n",
    "    g.add((URIRef(v['iri']), RDF.type, OWL.AnnotationProperty))\n",
    "    g.add((URIRef(v['iri']), RDFS.label, Literal(v['label'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add each row from the ontology dataframe to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (ix, label_path, parent_label_path, iri, parent_iri, annotation) in ontdf.itertuples(): # ontdf.head(100).itertuples():\n",
    "    if len(iri) > 0:\n",
    "        ## add iri to graph\n",
    "        g.add((URIRef(iri), RDF.type, OWL.Class))\n",
    "        g.add((URIRef(iri), RDFS.label, Literal(label_path)))\n",
    "        \n",
    "        ## add iri annotations to graph (note: annotation is a json string of form iri:value)\n",
    "        ann = json.loads(annotation)\n",
    "        for k, v in ann.items():\n",
    "            g.add((URIRef(iri), URIRef(k), Literal(v)))\n",
    "    \n",
    "    if len(parent_iri) > 0:\n",
    "        g.add((URIRef(iri), RDFS.subClassOf, URIRef(parent_iri))) # add parent iri to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save graph (note: different formats (e.g., turtle) are possible)\n",
    "g.serialize(destination='output/gold-classification-paths-translation.owl', format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
